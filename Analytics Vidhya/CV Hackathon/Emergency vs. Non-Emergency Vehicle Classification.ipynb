{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/cvhackathon/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/cvhackathon/test_vc2kHdQ.csv\")\nsample = pd.read_csv(\"/kaggle/input/cvhackathon/sample_submission_yxjOnvz.csv\")\nimg_dir = \"/kaggle/input/images/images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['emergency_or_not']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert('L') to convert to gray scale\nfrom PIL import Image\ntrain_images=np.array(train.iloc[:,0])\ntest_images=np.array(test.iloc[:,0])\ntrainimagearr=[]\nfor i in train_images:\n    img=Image.open(img_dir+i).resize((224,224))\n    trainimagearr.append(np.array(img))\ntestimagearr=[]\nfor i in test_images:\n    img=Image.open(img_dir+i).resize((224,224))\n    testimagearr.append(np.array(img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img=np.array(trainimagearr)\nprint(train_img.shape)\ntest_img=np.array(testimagearr)\nprint(test_img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_img[10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndir_train_emer = 'train/emergency'\ndir_train_non_emer = 'train/not_emergency'\n\ndir_valid_emer = 'valid/emergency'\ndir_valid_non_emer = 'valid/not_emergency'\n\nparent_dir = 'cv'\n\npath1 = os.path.join(parent_dir, dir_train_emer)\nos.makedirs(path1, exist_ok=True)\n\npath1 = os.path.join(parent_dir, dir_train_non_emer)\nos.makedirs(path1, exist_ok=True)\n\npath1 = os.path.join(parent_dir, dir_valid_emer)\nos.makedirs(path1, exist_ok=True)\n\npath1 = os.path.join(parent_dir, dir_valid_non_emer)\nos.makedirs(path1, exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in train.query('emergency_or_not==1')['image_names']:\n    path2 = os.path.join(img_dir, x)\n    img = Image.open(path2)\n    path_emer=os.path.join(parent_dir, dir_train_emer)\n    path_emer=os.path.join(path_emer,x)\n    img.save(path_emer)\n    \nfor x in train.query('emergency_or_not==0')['image_names']:\n    path2 = os.path.join(img_dir, x)\n    img = Image.open(path2)\n    path_emer=os.path.join(parent_dir, dir_train_non_emer)\n    path_emer=os.path.join(path_emer,x)\n    img.save(path_emer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nimport os\nimport keras\nimport numpy as np\nimport pandas as pd\nfrom zipfile import ZipFile\nfrom PIL import Image\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# VGG16","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import applications\nfrom keras.utils.np_utils import to_categorical\nimport math\n\nimg_width, img_height = 224,224\nepochs = 50\nbatch_size = 64\n\nvgg16 = applications.VGG16(include_top = False, weights='imagenet')\ndatagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n\ntrain_set = datagen.flow_from_directory('cv/train', target_size=(img_width, img_height), batch_size=batch_size, class_mode=None, shuffle=False)\n\nnb_train_samples = len(train_set.filenames) \nnum_classes = len(train_set.class_indices)  \npredict_size_train = int(math.ceil(nb_train_samples / batch_size))\n\ntrain_features = vgg16.predict_generator(train_set, predict_size_train)\nnp.save('train_features.npy', train_features)\n\ntrain_set_labels = datagen.flow_from_directory('cv/train', target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary', shuffle=False)\n\nnb_train_samples = len(train_set_labels.filenames) \nnum_classes = len(train_set_labels.class_indices)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = np.load('train_features.npy')  \ntrain_labels = train_set_labels.classes  \ntrain_labels = to_categorical(train_labels, num_classes=num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vggclassifier = Sequential() \nvggclassifier.add(Flatten(input_shape=train_data.shape[1:])) \n\nvggclassifier.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform')) # he_uniform\nvggclassifier.add(Dropout(0.3))\n\nvggclassifier.add(Dense(64, activation = 'relu', kernel_initializer='he_uniform')) # he_uniform\nvggclassifier.add(Dropout(0.3))\n\nvggclassifier.add(Dense(num_classes, activation = 'softmax', kernel_initializer='he_uniform')) # he_uniform\nvggclassifier.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\nvggclassifier.fit(train_data, train_labels, epochs=150, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nmain_result = []\n\nfor x in test['image_names']:\n    path2 = os.path.join(img_dir, x)\n    test_image = image.load_img(path2, target_size=(img_height, img_width))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis=0)\n    bt_prediction = vgg16.predict(test_image)\n    result = vggclassifier.predict(bt_prediction)\n    print(result)\n    main_result.append(result[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['emergency_or_not'] = main_result\nsample['emergency_or_not'] = np.where(sample['emergency_or_not']<0.6, 0, 1)\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('subvgg14.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet50","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50, preprocess_input\n\nHEIGHT = 224\nWIDTH = 224\n\nbase_model = ResNet50(weights='imagenet', \n                      include_top=False, \n                      input_shape=(HEIGHT, WIDTH, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nHEIGHT = 224\nWIDTH = 224\nBATCH_SIZE = 64\n\ntrain_datagen =  ImageDataGenerator(\n      preprocessing_function=preprocess_input,\n      rotation_range=90,\n      shear_range=0.2, \n      zoom_range=0.2,\n      horizontal_flip=True,\n      vertical_flip=True\n    )\n\ntrain_generator = train_datagen.flow_from_directory('cv/train', \n                                                    target_size=(HEIGHT, WIDTH), \n                                                    batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Activation, Flatten, Dropout\nfrom keras.models import Sequential, Model\n\ndef build_finetune_model(base_model, dropout, fc_layers, num_classes):\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    x = base_model.output\n    x = Flatten()(x)\n    for fc in fc_layers:\n        # New FC layer, random init\n        x = Dense(fc, activation='relu')(x) \n        x = Dropout(dropout)(x)\n\n    # New softmax layer\n    predictions = Dense(num_classes, activation='softmax')(x) \n    \n    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n\n    return finetune_model\n\nFC_LAYERS = [128, 64]\ndropout = 0.3\n\nfinetune_model = build_finetune_model(base_model, \n                                      dropout=dropout, \n                                      fc_layers=FC_LAYERS, \n                                      num_classes=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import SGD, Adam\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\n\nNUM_EPOCHS = 150\nBATCH_SIZE = 32\n\nadam = Adam(lr=0.00001)\nfinetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])\n\n# filepath=\"./checkpoints/\" + \"ResNet50\" + \"_model_weights.h5\"\n# checkpoint = ModelCheckpoint(filepath, monitor=[\"acc\"], verbose=1, mode='max')\n# callbacks_list = [checkpoint]\n\nhistory = finetune_model.fit_generator(train_generator, epochs=NUM_EPOCHS, \n                                       shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nmain_result = []\n\nfor x in test['image_names']:\n    path2 = os.path.join(img_dir, x)\n    test_image = image.load_img(path2, target_size=(HEIGHT, WIDTH))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis=0)\n    result = finetune_model.predict(test_image)\n    print(result)\n    main_result.append(result[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['emergency_or_not'] = main_result\nsample['emergency_or_not'] = np.where(sample['emergency_or_not']<0.80, 0, 1)\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('submres3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inception","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\n\n# create the base pre-trained model\nbase_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\n# add a global spatial average pooling layer\nx = base_model.output\nx = Flatten()(x)\n# x = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(32, activation='relu')(x)\nx = Dropout(0.3)(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit_generator(train_generator, epochs=100, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nmain_result = []\n\nfor x in test['image_names']:\n    path2 = os.path.join(img_dir, x)\n    test_image = image.load_img(path2, target_size=(HEIGHT, WIDTH))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis=0)\n    result = model.predict(test_image)\n    print(result)\n    main_result.append(result[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['emergency_or_not'] = main_result\nsample['emergency_or_not'] = np.where(sample['emergency_or_not']<1, 0, 1)\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv(\"inception.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensembling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [vggclassifier, finetune_model, model]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nmain_result = []\n\nfor x in test['image_names']:\n    path2 = os.path.join(img_dir, x)\n    test_image = image.load_img(path2, target_size=(HEIGHT, WIDTH))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis=0)\n    bt_prediction = vgg16.predict(test_image)\n    result = vggclassifier.predict(bt_prediction)[0][0]\n    pred = [result]\n    pred.append(finetune_model.predict(test_image)[0][0])\n    pred.append(model.predict(test_image)[0][0])\n    pred = np.array(pred)\n    if np.sum(pred, axis=0)>0.8:\n        result = 1\n    else:\n        result = 0\n    main_result.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample['emergency_or_not'] = main_result\n# sample['emergency_or_not'] = np.where(sample['emergency_or_not']<0.90, 0, 1)\nsample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv('ensemble11.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}